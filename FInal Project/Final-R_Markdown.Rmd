---
title: "Final: Effects of Air Pollution on Countries"
author: "DataSci Warriors (Group 5)"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate  
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
#Make sure you install the below packages by removing the comment - #
# install.packages("Rcpp")
# install.packages("tidyverse")
# install.packages("rworldmap")
# install.packages("tmap")
# install.packages("spData")
# install.packages("sf")
# install.packages("ggpubr")
library(ezids)
library(tidyverse) #install.packages("tidyverse")
library(rworldmap) #install.packages("rworldmap")
library(tmap) #install.packages("tmap")
library(sp) #install.packages("spData")
library(spData)
library(sf) #install.packages("sf")
library(ggpubr) #install.packages("ggpubr")
library(dplyr) #install.packages("dplyr")
library(knitr)
library(magrittr)
loadPkg("faraway")
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "show", message = F)
options(scientific=T, digits = 3) 
options(scipen=999)
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

# 1. Introduction

## Motivation

Climate issues are pervasive but typically disproportionately affect low income communities and developing countries. Our group wanted to explore how air pollution has changed over time and affect countries differently. Specifically, we wanted to analyze how a country's economic and social position can either increase, decrease, or not have observable impact on the affects of air pollution. In laymen terms, does air pollution affect underdeveloped countries disproportionately?

## Set Up

Before we start, we need to ensure that we have all the relevant libraries installed and imported.

Run these in the console, or only the ones that your system does not have, to install packages in addition to the ezids package.
```
install.packages("tidyverse")
install.packages("rworldmap")
install.packages("tmap")
install.packages("spData")
install.packages("sf")
install.packages("ggpubr")
install.packages("dplyr")
install.packages("knitr")
install.packages("magrittr")
```

# 2. Data Sources and Data Wrangling

## Data Sources
For our analysis, we will be working with 5 main data sources shown in the table below:


| Data                                                      | Source                | Link                                                                                       |
|-----------------------------------------------------------|-----------------------|--------------------------------------------------------------------------------------------|
| Deaths Due to Air Pollution of Countries from 1990 - 2017 | Kaggle                | [Link](https://www.kaggle.com/akshat0giri/death-due-to-air-pollution-19902017)             |
| GDP Annual Growth of Countries from 1960 - 2020           | Kaggle via WorldBank  | [Link](https://www.kaggle.com/zackerym/gdp-annual-growth-for-each-country-1960-2020)       |
| United Nations Population and Region Data                 | United Nations        | [Link](https://population.un.org/wpp/Download/Standard/Population/)                        |
| United Nations ISO-alpha3 code                            | United Nations        | [Link](https://unstats.un.org/unsd/methodology/m49/)                                       |
| spData for Map Geometries                                 | spData for Mapping    | [Link](https://nowosad.github.io/spData/)                                                  |
: Figure 1: Data Sources

The main variables in our datasets will include:

| Feature                         | Data Type               | Unit of Measure       | Notes and Assumptions                                                                      |
|---------------------------------|-------------------------|-----------------------|--------------------------------------------------------------------------------------------|
| GDP (Gross Domestic Product)    | Numerical, Continuous   | $USD                  | This is our chosen proxy for measuring a country's economic status                               |
| Population Size                 | Numerical, Continuous   | thousands of people   | Annual UN estimated                                                                        |
| Deaths due to Air Pollution     | Numerical, Continuous   | deaths per million    | This is our chosen proxy for measuring the negative affects of air pollution.              |
| Country                         | Qualitative, Categorical| N/A                   | 231 countries                                                                              |
| SDG Region                      | Qualitative, Categorical| N/A                   | UN's Sustainable Development Goals Region Classification.                                  |
| Sub Region                      | Qualitative, Categorical| N/A                   | UN's Sustainable Development Goals Sub-Region Classification.                              |
| ISO-alpha3 Country Code         | Qualitative, Categorical| N/A                   | Standard for identifying countries (text ID).                                              |
| ISO-alpha2 Country Code         | Qualitative, Categorical| N/A                   | Another standard for identifying countries (text ID).                                      |
| M49 Country Code                | Numerical, Categorical  | N/A                   | Another standard for identifying countries (numerical ID).                                 |
| Year                            | Numerical, Categorical  | N/A                   | 1990 to 2017                                                                               |
| GDP per Capita                  | Numerical, Continuous   | $USD per person       | Normalization of GDP to compare between population sizes (calculated).                     |
: Figure 2: Key Variables


## Data Wrangling
While data from Kaggle are already in a format to be cleaned, downloaded data from United Nations required a little data wrangling. Mainly, we needed to extract just countries' data from the Excel workbooks and into their own contained csv files. Since we only need to do this once and programming it would take significant time to choose the specific cells that we need, we opted to perform this step outside of R and in Excel. Note that if this were a part of a real production data pipeline, we would take the time to program the data extraction but would likely choose a different programming language such as Python that is a bit more robust in these types of tasks like web scraping and data transformations in Pandas.

![UN Data Sample Messy](images/un_excel_mess.png)
: *Figure 3: Sample screenshot of data downloaded from UN including unnecessary elements like banners and other regional data.*


![UN Data Sample Cleaned](images/un_excel_cleaned.png)
: *Figure 4: Sample screenshot of transformed UN dataset.*

# 3. Load, Clean, and Inspect Data

## Load Data

```{r 3.1, results =T, echo=F}
country_codes_df <- read.csv("data/country_codes.csv", header = TRUE, sep = ",")
air_pollution_df <- read.csv("data/death-rates-from-air-pollution.csv", header = TRUE, sep = ",")
gdp_df <- read.csv("data/GDP_annual_growth.csv", header = TRUE, sep = ",")
population_region_df <- read.csv("data/population_in_thousands_region.csv", header = TRUE, sep = ",")
```

```{r 3.2, results =T, echo=F}
#str(country_codes_df)
data.frame(variable = names(country_codes_df),
           class = sapply(country_codes_df, typeof),
           first_values = sapply(country_codes_df, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL) %>% 
kable(caption='Figure 5: Structure of country_codes_df')
```

```{r 3.3, results =T, echo=F}
#str(air_pollution_df)
data.frame(variable = names(air_pollution_df),
           class = sapply(air_pollution_df, typeof),
           first_values = sapply(air_pollution_df, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL) %>% 
kable(caption='Figure 6: Structure of air_pollution_df')
```


```{r 3.4, results =T, echo=F}
#str(gdp_df)
head(data.frame(variable = names(gdp_df),
           class = sapply(gdp_df, typeof),
           first_values = sapply(gdp_df, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL), 10) %>% 
kable(caption='Figure 7: Structure of gdp_df, not showing all years in table to retain space but years go up to X2020')
```


```{r 3.5, results =T, echo=F}
#str(population_region_df)
head(data.frame(variable = names(population_region_df),
           class = sapply(population_region_df, typeof),
           first_values = sapply(population_region_df, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL), 10) %>% 
kable(caption='Figure 8: Structure of population_region_df, not showing all years in table to retain space but years go up to X2020')
```


```{r 3.5.1, results =T, echo=F}
#str(world)
head(data.frame(variable = names(world),
           class = sapply(world, typeof),
           first_values = sapply(world, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL), 10) %>% 
kable(caption='Figure 9: Structure of world, not showing geom feature in table as it has unique list of values per row and therefore is extremely large to display.')
```

## Clean Data

First thing that we need to drop unnecessary columns and set datatypes (factor, num, etc.).

### Clean *air_pollution_df*:
```{r 3.6, results =T, echo=F}
# Remove columns
air_pollution_df_cleaned <- subset(air_pollution_df, select = -c(Indoor.air.pollution..deaths.per.100.000., Outdoor.particulate.matter..deaths.per.100.000., Outdoor.ozone.pollution..deaths.per.100.000.))
# Set datatypes
air_pollution_df_cleaned$Entity = factor(air_pollution_df_cleaned$Entity)
air_pollution_df_cleaned$Code = factor(air_pollution_df_cleaned$Code)
air_pollution_df_cleaned$Year = factor(air_pollution_df_cleaned$Year)
# Rename columns
air_pollution_df_cleaned <- rename(air_pollution_df_cleaned, Country = Entity, ISO.alpha3.code = Code, Deaths.Air.Pollution.per.100k = Air.pollution..total...deaths.per.100.000.)
#str(air_pollution_df_cleaned)
data.frame(variable = names(air_pollution_df_cleaned),
           class = sapply(air_pollution_df_cleaned, typeof),
           first_values = sapply(air_pollution_df_cleaned, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL) %>% 
kable(caption='Figure 10: Structure of air_pollution_df_cleaned')
```

### Clean *gdp_df*:
```{r 3.7, results =T, echo=F}
# Remove columns
gdp_df_cleaned <- subset(gdp_df, select = -c(Indicator.Name, Indicator.Code))
# Pivot wide to long dataset (data melt)
gdp_df_cleaned <- gdp_df_cleaned %>%
  pivot_longer(
    cols = starts_with("X"), 
    names_to = "Year", 
    values_to = "GDP.USD", 
    values_drop_na = TRUE
  )
# Remove characters from column
gdp_df_cleaned$Year<-gsub("X","",as.character(gdp_df_cleaned$Year))
# Set datatypes
gdp_df_cleaned$Country.Name = factor(gdp_df_cleaned$Country.Name)
gdp_df_cleaned$Country.Code = factor(gdp_df_cleaned$Country.Code)
gdp_df_cleaned$Year = factor(gdp_df_cleaned$Year)
# Rename columns
gdp_df_cleaned <- rename(gdp_df_cleaned, Country = Country.Name, ISO.alpha3.code = Country.Code)
#str(gdp_df_cleaned)
data.frame(variable = names(gdp_df_cleaned),
           class = sapply(gdp_df_cleaned, typeof),
           first_values = sapply(gdp_df_cleaned, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL) %>% 
kable(caption='Figure 11: Structure of gdp_df_cleaned')
```

### Clean *population_region_df*:
```{r 3.8, results =T, echo=F}
# Remove columns
population_region_df_cleaned <- subset(population_region_df, select = -c(Notes, Type, Parent.code))
# Pivot wide to long dataset (data melt)
population_region_df_cleaned <- population_region_df_cleaned %>%
  pivot_longer(
    cols = starts_with("X"), 
    names_to = "Year", 
    values_to = "Population.thousands", 
    values_drop_na = TRUE
  )
# Remove characters from column
population_region_df_cleaned$Year<-gsub("X","",as.character(population_region_df_cleaned$Year))
population_region_df_cleaned <- as.data.frame(apply(population_region_df_cleaned, 2, function(x) gsub("\\s+", "", x))) 
# Set datatypes
population_region_df_cleaned$Country = factor(population_region_df_cleaned$Country)
population_region_df_cleaned$SDGRegion = factor(population_region_df_cleaned$SDGRegion)
population_region_df_cleaned$Country.code = factor(population_region_df_cleaned$Country.code)
population_region_df_cleaned$SubRegion = factor(population_region_df_cleaned$SubRegion)
population_region_df_cleaned$Year = factor(population_region_df_cleaned$Year)
population_region_df_cleaned$Population.thousands = as.numeric(population_region_df_cleaned$Population.thousands)
# Rename columns
population_region_df_cleaned <- rename(population_region_df_cleaned, M49.code = Country.code)
#str(population_region_df_cleaned)
data.frame(variable = names(population_region_df_cleaned),
           class = sapply(population_region_df_cleaned, typeof),
           first_values = sapply(population_region_df_cleaned, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL) %>% 
kable(caption='Figure 12: Structure of population_region_df_cleaned')
```

### Clean *population_region_df*:
```{r 3.9, results =T, echo=F}
# Set datatypes
country_codes_df$M49.code = factor(country_codes_df$M49.code)
country_codes_df$Country.or.Area = factor(country_codes_df$Country.or.Area)
country_codes_df$ISO.alpha3.code = factor(country_codes_df$ISO.alpha3.code)
country_codes_df$ISO.alpha2.code = factor(country_codes_df$ISO.alpha2.code)
#str(country_codes_df)
data.frame(variable = names(country_codes_df),
           class = sapply(country_codes_df, typeof),
           first_values = sapply(country_codes_df, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL) %>% 
kable(caption='Figure 13: Structure of country_codes_df')
```

### Clean *world*:
```{r 3.9.5, results =T, echo=F}
# Set datatypes
world$iso_a2 = factor(world$iso_a2)
# Remove columns
world_df_cleaned <- subset(world, select = c(iso_a2, geom))
#str(world_df_cleaned)
head(data.frame(variable = names(world_df_cleaned),
           class = sapply(world_df_cleaned, typeof),
           first_values = sapply(world_df_cleaned, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL), 1) %>% 
kable(caption='Figure 14: Structure of world_df_cleaned, not showing geom feature in table as it has unique list of values per row and therefore is extremely large to display.')
```

Note that we only have geometries for 175 countries, some will not be able to be plot on a map but that is okay.

### Final DataFrame Construction
Now let's merge our 4 datasets into one using a series of inner joins using country code and year as keys depending on the specific join. We are using inner joins because we want to drop all null values which would mean either a country does not have a country code or we have more years of data than our smallest year range (the air pollution dataset).

```{r 3.10, results =T, echo=F}
# Join datasets
final_df <- merge(x = air_pollution_df_cleaned, y = country_codes_df, by = 'ISO.alpha3.code')
final_df <- merge(x = final_df, y = gdp_df_cleaned, by = c('ISO.alpha3.code', 'Year'))
final_df <- merge(x = final_df, y = population_region_df_cleaned, by = c('M49.code', 'Year'))
final_df <- merge(x = final_df, y = world_df_cleaned, by.x = 'ISO.alpha2.code', by.y = 'iso_a2', all.x = TRUE) #left join
# Remove columns
final_df <- subset(final_df, select = -c(Country.or.Area, Country.y, Country))
# Calculate GDP per capita 
final_df$gdp.per.capita <- final_df$GDP.USD / (final_df$Population.thousands * 1000)
#str(final_df)
data.frame(variable = names(final_df),
           class = sapply(final_df, typeof),
           first_values = sapply(final_df, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL) %>% 
kable(caption='Figure 15: Structure of final_df')
```

Our dataset is finally ready to be analyzed.

# 4. Main Research Question

## Do lower GDP countries have more deaths per 100k due to air pollution?

### Is there a correlation between GDP per capita and deaths caused by pollution? Is it linear? How strong is the correlation?

#### Linear Fit
Let's first look at the general fit on the overall data.

```{r 5.1, include=TRUE, fig.align="center", echo=F}
fit1 <- lm(Deaths.Air.Pollution.per.100k ~ gdp.per.capita, data=final_df_sf)
ggplot(final_df_sf, aes(gdp.per.capita, Deaths.Air.Pollution.per.100k)) +
  geom_point() +
  geom_smooth(method='lm', se=FALSE) +
  stat_regline_equation(label.y = 400, aes(label = ..eq.label..)) +
  stat_regline_equation(label.y = 350, aes(label = ..rr.label..))
```
: *Figure 44: Linear model (fit1) on overall data, deaths due to air pollution per 100k vs GDP per capita, 1990 to 2017.*

From the plot, we observe that there is indeed a negative correlation between deaths due to air pollution per 100k and GDP per capita. However, the strength of that relationship is not particularly strong as the R^2^ is really low at `r summary(fit1)$r.squared`. This means that only 29% of the variance experienced in deaths due to air pollution per 100k is caused by GDP per capita in a linear relationship.

Even looking at each individual SDGRegion, their linear fits get better overall but are still not particularly strong with the highest being Australia/New Zealand and Europe at R^2^ of 0.56 and 0.55 respectively.

```{r 5.2, include=TRUE, fig.align="center", echo=F}
ggplot(final_df_sf, aes(gdp.per.capita, Deaths.Air.Pollution.per.100k)) +
  geom_point(size=0.75) +
  geom_smooth(method='lm') +
  stat_regline_equation(label.y = 350,  aes(label = ..eq.label..), size=2) +
  stat_regline_equation(label.y = 300, aes(label = ..rr.label..), size=2) +
  theme_grey(base_size = 7) +
  facet_wrap(~SDGRegion, ncol = 3, scales='free')
```
: *Figure 45: Linear models for each SDGRegion, deaths due to air pollution per 100k vs GDP per capita, 1990 - 2017.*

Let's now look at how slicing by annual changes plays a part.

```{r 5.2.5, include=TRUE, fig.align="center", echo=F}
ggplot(final_df_sf, aes(gdp.per.capita, Deaths.Air.Pollution.per.100k)) +
  geom_point(size=0.25) +
  geom_smooth(method='lm') +
  stat_regline_equation(label.y = 350,  aes(label = ..eq.label..), size=1.5) +
  stat_regline_equation(label.y = 300, aes(label = ..rr.label..), size=1.5) +
  theme_grey(base_size = 4) +
  facet_wrap(~Year, ncol = 7, scales='free')
```
: *Figure 46: Linear models for each Year, deaths due to air pollution per 100k vs GDP per capita, 1990 - 2017.*


As observed, time does not seem to play a significant part in describing the relationship between deaths due to air pollution per 100k vs GDP per capita as the R^2^ stays roughly constant around 0.3 across all the years.

#### Transformed Log Scale - Linear Fit

Perhaps we should look at a non-linear fit. From our visuals, we see that every plot starts off at really high deaths due to air pollution per 100k then drops off dramatically as GDP per capita increases. However, the drop off begins to tamper off and asymptotically approaches some value. (*It will be interesting to see if we can generalize what that GDP per capita value is. Let's table that for later.*) We have seen this type of behavior before in log graphs such as one shown below.

![Sample Log Graph](images/sample_log_graph.png)
: *Figure 47: Sample log graph.*

Our data seems to be a -log(x) instead of log(x). Let's transform our linear fit to a log fit by wrapping our features into a log() function and fitting back to a linear fit and see what the relationship is.

fit2's summary statistics are:

```{r 5.3, include=TRUE, fig.align="center", echo=F}
fit2 <- lm(log(Deaths.Air.Pollution.per.100k) ~ log(gdp.per.capita), data=final_df_sf)
summary(fit2)
# print(vif(fit2))
```

Let's replot with this new fit.

```{r 5.3.1, include=TRUE, fig.align="center", echo=F}
ggplot(final_df_sf, aes(log(gdp.per.capita), log(Deaths.Air.Pollution.per.100k))) +
  geom_point(size=0.75) +
  geom_smooth(method='lm') +
  stat_regline_equation(label.y = 7,  aes(label = ..eq.label..), size=2) +
  stat_regline_equation(label.y = 6, aes(label = ..rr.label..), size=2) +
  theme_grey(base_size = 7) +
  facet_wrap(~SDGRegion, ncol = 3, scales='free')
```
: *Figure 48 Fitting to a log(y) = (m)(log(x)) + b curve yields much stronger relationship by SDGRegion.*

```{r 5.3.2, include=TRUE, fig.align="center", echo=F}
ggplot(final_df_sf, aes(log(gdp.per.capita), log(Deaths.Air.Pollution.per.100k))) +
  geom_point(size=0.25) +
  geom_smooth(method='lm') +
  stat_regline_equation(label.y = 7,  aes(label = ..eq.label..), size=1.5) +
  stat_regline_equation(label.y = 6, aes(label = ..rr.label..), size=1.5) +
  theme_grey(base_size = 4) +
  facet_wrap(~Year, ncol = 7, scales='free')
```
: *Figure 49: Fitting to a log(y) = (m)(log(x)) + b curve yields much stronger relationship by years.*

```{r 5.3.3, include=TRUE, fig.align="center", echo=F}
ggplot(final_df_sf, aes(log(gdp.per.capita), log(Deaths.Air.Pollution.per.100k))) +
  geom_point() +
  geom_smooth(method='lm', se=FALSE) +
  stat_regline_equation(label.y = 7, aes(label = ..eq.label..)) +
  stat_regline_equation(label.y = 6, aes(label = ..rr.label..))
```
: *Figure 50: Fitting to a log(y) = (m)(log(x)) + b curve yields much stronger relationship.*

Across the board, the strength of our linear relationship increases dramatically when first transforming both features by the log() function first. The new R^2^ is now `r summary(fit2)$r.squared` which means around 74% of the variance in our target feature can be explained by this mathematical relationship.

Let's test a few more regression models by adding more features and see what happens.

```{r 5.4, include=TRUE, fig.align="center", echo=T}
fit3 <- lm(log(Deaths.Air.Pollution.per.100k) ~ log(gdp.per.capita)*SubRegion, data=final_df_sf)
fit4 <- lm(log(Deaths.Air.Pollution.per.100k) ~ log(gdp.per.capita)*SubRegion+Year, data=final_df_sf)
fit5 <- lm(log(Deaths.Air.Pollution.per.100k) ~ log(gdp.per.capita)*Year, data=final_df_sf)
```
R^2^ values for adding more features are in fit3, fit4, and fit5 are `r summary(fit3)$r.squared`, `r summary(fit4)$r.squared`, and `r summary(fit5)$r.squared` respectively.

Let's check out the VIFs to see if we should keep any of our new models.

```{r Q5.4.1, include=FALSE}
knitr::opts_chunk$set(warning = F, results = "show", message = F)
```
```{r Q5.4.2, include=TRUE, echo=F}
xkablevif(fit3, title='Figure 51: VIF of lm(log(Deaths.Air.Pollution.per.100k) ~ log(gdp.per.capita)*SubRegion+Year')
```

```{r Q5.4.3, include=TRUE, echo=F}
xkablevif(fit4, title='Figure 52: VIF of lm(log(Deaths.Air.Pollution.per.100k) ~ log(gdp.per.capita)*SubRegion+Year.')
```

```{r Q5.4.4, include=TRUE, echo=F}
xkablevif(fit5, title='Figure 53: VIF of lm(log(Deaths.Air.Pollution.per.100k) ~ log(gdp.per.capita)*Year.')
```

```{r Q5.4.5, include=FALSE}
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
```

Although adding more features into our regression model results in higher R^2^ values, the Variance Inflation Factor (VIF) for each are extremely high so we will reject those models as those added features are highly correlated with each other. Therefore, we will stick with our second model fit2.

We can then predict a country's deaths caused from air pollution in a given year by using the country's GDP per capita with the following equation: 


$$
log(Deaths_{from~air~pollution|per~year|per~country} / 100,000) = 7.38778 - 0.38952 * log(GDP_{per capita}) ~~~~~~~~~~~~~~~~  eqn (1)
$$

or solving for our target variable:



$$
Deaths_{from~air~pollution|per~year|per~country} = 10^{7.38778 - 0.38952 * log(GDP per capita)} * 100,000 ~~~~~~~~~~~~~~~~ eqn (2)
$$

### Is there a difference in means of death caused by pollution between low, mid, and high GDP per capita?

We all know that correlation does not necessarily mean causation. Let us dig a little deeper and test if means of deaths caused by air pollution per 100k across different GDP per capita levels are equal or not.

#### One-Way ANOVA Test

We start off by performing a One-Way ANOVA test to determine if the means of deaths caused by air pollution per 100k across different GDP per capita levels are equal or not.

H~0~: $\mu$~deaths_lowest_gdp~ = $\mu$~deaths_low_gdp~ = $\mu$~deaths_medium_gdp~ = $\mu$~deaths_high_gdp~

H~1~: At least one of $\mu$~deaths_lowest_gdp~, $\mu$~deaths_low_gdp~, $\mu$~deaths_medium_gdp~, $\mu$~deaths_high_gdp~ is not equal

We will use an $\alpha$ value of 0.05.

```{r Q5.9, include=TRUE, echo=F}
# divide df$am.spent 
final_df_sf$qnt <- cut(final_df_sf$gdp.per.capita , breaks=quantile(final_df_sf$gdp.per.capita, na.rm = TRUE),
                                    labels=1:4, include.lowest=TRUE)
# check ranges
tapply(final_df_sf$gdp.per.capita , final_df_sf$qnt , range)
deaths_aov = aov(Deaths.Air.Pollution.per.100k ~ qnt, data=final_df_sf)
deaths_aovsummary = summary(deaths_aov)
deaths_aovsummary
p = deaths_aovsummary[[1]][["Pr(>F)"]][[1]]
```
The p-value~test1~ is `r format(p, scientific=T)`, which is lower than $\alpha$~0.05~. Therefore, we reject our null hypothesis that $\mu$~deaths_lowest_gdp~ = $\mu$~deaths_low_gdp~ = $\mu$~deaths_medium_gdp~ = $\mu$~deaths_high_gdp~. This means that there is statistically significant that at least one of the means of deaths in low, medium, and high GDP per capita are not the same. 

#### 2-Sample T-Tests

We will conduct 6 2-sample t-tests to determine if each of the groupings are different from each other:

* Lowest GDP per capita's deaths does not equal Low GDP per capita's deaths
    + H~0~: $\mu$~deaths_lowest_gdp~ = $\mu$~deaths_low_gdp~
    + H~1~: $\mu$~deaths_lowest_gdp~ != $\mu$~deaths_low_gdp~
* Low GDP per capita's deaths does not equal Medium GDP per capita's deaths
    + H~0~: $\mu$~deaths_low_gdp~ = $\mu$~deaths_medium_gdp~
    + H~1~: $\mu$~deaths_low_gdp~ != $\mu$~deaths_medium_gdp~
* Medium GDP per capita's deaths does not equal High GDP per capita's deaths
    + H~0~: $\mu$~deaths_medium_gdp~ = $\mu$~deaths_high_gdp~
    + H~1~: $\mu$~deaths_medium_gdp~ != $\mu$~deaths_high_gdp~
* Lowest GDP per capita's deaths does not equal High GDP per capita's deaths
    + H~0~: $\mu$~deaths_lowest_gdp~ = $\mu$~deaths_high_gdp~
    + H~1~: $\mu$~deaths_lowest_gdp~ != $\mu$~deaths_high_gdp~
* Lowest GDP per capita's deaths does not equal Medium GDP per capita's deaths
    + H~0~: $\mu$~deaths_lowest_gdp~ = $\mu$~deaths_medium_gdp~
    + H~1~: $\mu$~deaths_lowest_gdp~ != $\mu$~deaths_medium_gdp~
* Low GDP per capita's deaths does not equal Highest GDP per capita's deaths
    + H~0~: $\mu$~deaths_low_gdp~ = $\mu$~deaths_high_gdp~
    + H~1~: $\mu$~deaths_low_gdp~ != $\mu$~deaths_high_gdp~
    
We will use a two sample t-test for each and use an $\alpha$ value of 0.05.

**Test 1**:

```{r Q5.9.1, include=TRUE, echo=F}
ttest1 = t.test(Deaths.Air.Pollution.per.100k ~ qnt==c(1,2), data=final_df_sf, conf=0.95)
ttest1
```

p-value~test1~: `r format(ttest1$p.value, scientific=T)`

p-value~test1~ < $\alpha$~0.05~ = `r ttest1$p.value < 0.05`

Conclusion of test1: p-value~test1~ is less than $\alpha$~0.05~, therefore we reject our null hypothesis that $\mu$~deaths_lowest_gdp~ is equal to $\mu$~deaths_low_gdp~ and accept our alternative hypothesis.

**Test 2**:

```{r Q5.9.2, include=TRUE, echo=F}
ttest2 = t.test(Deaths.Air.Pollution.per.100k ~ qnt==c(2,3), data=final_df_sf, conf=0.95)
ttest2
```

p-value~test2~: `r format(ttest2$p.value, scientific=T)`

p-value~test2~ < $\alpha$~0.05~ = `r ttest2$p.value < 0.05`

Conclusion of test2: p-value~test2~ is less than $\alpha$~0.05~, therefore we reject our null hypothesis that $\mu$~deaths_low_gdp~ is equal to $\mu$~deaths_medium_gdp~ and accept our alternative hypothesis.

**Test 3**:

```{r Q5.9.3, include=TRUE, echo=F}
ttest3 = t.test(Deaths.Air.Pollution.per.100k ~ qnt==c(3,4), data=final_df_sf, conf=0.95)
ttest3
```

p-value~test3~: `r format(ttest3$p.value, scientific=T)`

p-value~test3~ < $\alpha$~0.05~ = `r ttest3$p.value < 0.05`

Conclusion of test3: p-value~test3~ is less than $\alpha$~0.05~, therefore we reject our null hypothesis that $\mu$~deaths_medium_gdp~ is equal to $\mu$~deaths_high_gdp~ and accept our alternative hypothesis.

**Test 4**:

```{r Q5.9.4, include=TRUE, echo=F}
ttest4 = t.test(Deaths.Air.Pollution.per.100k ~ qnt==c(1,4), data=final_df_sf, conf=0.95)
ttest4
```

p-value~test4~: `r format(ttest4$p.value, scientific=T)`

p-value~test4~ < $\alpha$~0.05~ = `r ttest4$p.value < 0.05`

Conclusion of test4: p-value~test4~ is less than $\alpha$~0.05~, therefore we reject our null hypothesis that $\mu$~deaths_lowest_gdp~ is equal to $\mu$~deaths_high_gdp~ and accept our alternative hypothesis.

**Test 5**:

```{r Q5.9.5, include=TRUE, echo=F}
ttest5 = t.test(Deaths.Air.Pollution.per.100k ~ qnt==c(1,3), data=final_df_sf, conf=0.95)
ttest5
```

p-value~test5~: `r format(ttest5$p.value, scientific=T)`

p-value~test5~ < $\alpha$~0.05~ = `r ttest5$p.value < 0.05`

Conclusion of test5: p-value~test5~ is less than $\alpha$~0.05~, therefore we reject our null hypothesis that $\mu$~deaths_lowest_gdp~ is equal to $\mu$~deaths_medium_gdp~ and accept our alternative hypothesis.

**Test 6**:

```{r Q5.9.6, include=TRUE, echo=F}
ttest6 = t.test(Deaths.Air.Pollution.per.100k ~ qnt==c(2,4), data=final_df_sf, conf=0.95)
ttest6
```

p-value~test6~: `r format(ttest6$p.value, scientific=T)`

p-value~test6~ < $\alpha$~0.05~ = `r ttest6$p.value < 0.05`

Conclusion of test6: p-value~test6~ is less than $\alpha$~0.05~, therefore we reject our null hypothesis that $\mu$~deaths_low_gdp~ is equal to $\mu$~deaths_high_gdp~ and accept our alternative hypothesis.

# 5. Conclusion- Main Research

### Main Research Results
From all of our tests, we can confirm that the means of deaths caused by air pollution are statistically significant when grouped by different levels of GDP per capita. This reinforces the idea that deaths caused by air pollution has a significant relationship with GDP per capita and the model can be quantified by *Equation 2*:

$$
Deaths_{from~air~pollution|per~year|per~country} = 10^{7.38778 - 0.38952 * log(GDP per capita)} * 100,000 ~~~~~~~~~~~~~~~~ eqn (2)
$$

The strength of the correlation can be quantified by our R^2^ value of `r summary(fit2)$r.squared` from Figure 50.

#Smart Questions for Modeling 

# 6. Smart Questions for Further Modeling 

### 1. What are the impacts of population size on GDP and Deaths due to Air Pollution globally?

### 2. What are the effects of (low or high) GDP and population size on deaths due to air pollution in Sub-Saharan Africa?

### 3. Can we let the data tell us what type of groupings exist in our dataset? How consistent are they to our preconceived groupings such as region or developed vs developing countries? 

### 4. Can we make a prediction of the future GDP by considering the population size, location, and the reation of population and deaths due to air pollution? 

# 7. Conclusion SMART Modeling

# 8. Bibliography

| Number                                                      | APA Citation                                                                                       |
|-----------------------------------------------------------|--------------------------------------------------------------------------------------------|
| 1                                        | Robin Lovelace, J. N. (n.d.). Chapter 8 Making maps with R: Geocomputation with R. Retrieved October 28, 2021, from https://geocompr.robinlovelace.net/adv-map.html                                  |
| 2                                     | Robin Lovelace, J. N. (2021, October 28). Chapter 2 Geographic data in R: Geocomputation with R. Retrieved from https://geocompr.robinlovelace.net/spatial-class.html#intro-sf                     |
| 3                                          | Hadley Wickham, D. N. (2021, October 28). 6 Maps. Retrieved from https://ggplot2-book.org/maps.html                                                |
| 4                                      | Customizing ggplot2 color and fill scales. (2021, October 28). Retrieved from https://spielmanlab.github.io/introverse/articles/color_fill_scales.html           |
| 5                                          | Logarithmic Functions. (2021, October 28). Retrieved from https://saylordotorg.github.io/text_intermediate-algebra/s10-03-logarithmic-functions-and-thei.html         |
: Figure 54: References

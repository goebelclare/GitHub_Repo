---
title: "Final: Effects of Air Pollution on Countries"
author: "DataSci Warriors (Group 5)"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate  
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
#Make sure you install the below packages by removing the comment - #
# install.packages("Rcpp")
# install.packages("tidyverse")
# install.packages("rworldmap")
# install.packages("tmap")
# install.packages("spData")
# install.packages("sf")
# install.packages("ggpubr")
library(ezids)
library(tidyverse) #install.packages("tidyverse")
library(rworldmap) #install.packages("rworldmap")
library(tmap) #install.packages("tmap")
library(sp) #install.packages("spData")
library(spData)
library(sf) #install.packages("sf")
library(ggpubr) #install.packages("ggpubr")
library(dplyr) #install.packages("dplyr")
library(knitr)
library(magrittr)
library(factoextra) #install.packages("factoextra")
library(cluster)
loadPkg("faraway")
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = FALSE, results = "show", message = F)
options(scientific=T, digits = 3) 
options(scipen=999)
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

# 1. Introduction

## Motivation

Climate issues are pervasive but typically disproportionately affect low income communities and developing countries. Our group wanted to explore how air pollution has changed over time and affect countries differently. Specifically, we wanted to analyze how a country's economic and social position can either increase, decrease, or not have observable impact on the affects of air pollution. In laymen terms, does air pollution affect underdeveloped countries disproportionately?

## Set Up

Before we start, we need to ensure that we have all the relevant libraries installed and imported.

Run these in the console, or only the ones that your system does not have, to install packages in addition to the ezids package.
```
install.packages("tidyverse")
install.packages("rworldmap")
install.packages("tmap")
install.packages("spData")
install.packages("sf")
install.packages("ggpubr")
install.packages("dplyr")
install.packages("knitr")
install.packages("magrittr")
```

# 2. Data Sources and Data Wrangling

## Data Sources
For our analysis, we will be working with 5 main data sources shown in the table below:


| Data                                                      | Source                | Link                                                                                       |
|-----------------------------------------------------------|-----------------------|--------------------------------------------------------------------------------------------|
| Deaths Due to Air Pollution of Countries from 1990 - 2017 | Kaggle                | [Link](https://www.kaggle.com/akshat0giri/death-due-to-air-pollution-19902017)             |
| GDP Annual Growth of Countries from 1960 - 2020           | Kaggle via WorldBank  | [Link](https://www.kaggle.com/zackerym/gdp-annual-growth-for-each-country-1960-2020)       |
| United Nations Population and Region Data                 | United Nations        | [Link](https://population.un.org/wpp/Download/Standard/Population/)                        |
| United Nations ISO-alpha3 code                            | United Nations        | [Link](https://unstats.un.org/unsd/methodology/m49/)                                       |
| spData for Map Geometries                                 | spData for Mapping    | [Link](https://nowosad.github.io/spData/)                                                  |
: Figure 1: Data Sources

The main variables in our datasets will include:

| Feature                         | Data Type               | Unit of Measure       | Notes and Assumptions                                                                      |
|---------------------------------|-------------------------|-----------------------|--------------------------------------------------------------------------------------------|
| GDP (Gross Domestic Product)    | Numerical, Continuous   | $USD                  | This is our chosen proxy for measuring a country's economic status                               |
| Population Size                 | Numerical, Continuous   | thousands of people   | Annual UN estimated                                                                        |
| Deaths due to Air Pollution     | Numerical, Continuous   | deaths per million    | This is our chosen proxy for measuring the negative affects of air pollution.              |
| Country                         | Qualitative, Categorical| N/A                   | 231 countries                                                                              |
| SDG Region                      | Qualitative, Categorical| N/A                   | UN's Sustainable Development Goals Region Classification.                                  |
| Sub Region                      | Qualitative, Categorical| N/A                   | UN's Sustainable Development Goals Sub-Region Classification.                              |
| ISO-alpha3 Country Code         | Qualitative, Categorical| N/A                   | Standard for identifying countries (text ID).                                              |
| ISO-alpha2 Country Code         | Qualitative, Categorical| N/A                   | Another standard for identifying countries (text ID).                                      |
| M49 Country Code                | Numerical, Categorical  | N/A                   | Another standard for identifying countries (numerical ID).                                 |
| Year                            | Numerical, Categorical  | N/A                   | 1990 to 2017                                                                               |
| GDP per Capita                  | Numerical, Continuous   | $USD per person       | Normalization of GDP to compare between population sizes (calculated).                     |
: Figure 2: Key Variables


## Data Wrangling
While data from Kaggle are already in a format to be cleaned, downloaded data from United Nations required a little data wrangling. Mainly, we needed to extract just countries' data from the Excel workbooks and into their own contained csv files. Since we only need to do this once and programming it would take significant time to choose the specific cells that we need, we opted to perform this step outside of R and in Excel. Note that if this were a part of a real production data pipeline, we would take the time to program the data extraction but would likely choose a different programming language such as Python that is a bit more robust in these types of tasks like web scraping and data transformations in Pandas.

![UN Data Sample Messy](images/un_excel_mess.png)
: *Figure 3: Sample screenshot of data downloaded from UN including unnecessary elements like banners and other regional data.*


![UN Data Sample Cleaned](images/un_excel_cleaned.png)
: *Figure 4: Sample screenshot of transformed UN dataset.*

# 3. Load, Clean, and Inspect Data

## Load Data

```{r 3.1, results =T, echo=F}
country_codes_df <- read.csv("data/country_codes.csv", header = TRUE, sep = ",")
air_pollution_df <- read.csv("data/death-rates-from-air-pollution.csv", header = TRUE, sep = ",")
gdp_df <- read.csv("data/GDP_annual_growth.csv", header = TRUE, sep = ",")
population_region_df <- read.csv("data/population_in_thousands_region.csv", header = TRUE, sep = ",")
```

```{r 3.2, results =T, echo=F}
#str(country_codes_df)
data.frame(variable = names(country_codes_df),
           class = sapply(country_codes_df, typeof),
           first_values = sapply(country_codes_df, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL) %>% 
kable(caption='Figure 5: Structure of country_codes_df')
```

```{r 3.3, results =T, echo=F}
#str(air_pollution_df)
data.frame(variable = names(air_pollution_df),
           class = sapply(air_pollution_df, typeof),
           first_values = sapply(air_pollution_df, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL) %>% 
kable(caption='Figure 6: Structure of air_pollution_df')
```


```{r 3.4, results =T, echo=F}
#str(gdp_df)
head(data.frame(variable = names(gdp_df),
           class = sapply(gdp_df, typeof),
           first_values = sapply(gdp_df, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL), 10) %>% 
kable(caption='Figure 7: Structure of gdp_df, not showing all years in table to retain space but years go up to X2020')
```


```{r 3.5, results =T, echo=F}
#str(population_region_df)
head(data.frame(variable = names(population_region_df),
           class = sapply(population_region_df, typeof),
           first_values = sapply(population_region_df, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL), 10) %>% 
kable(caption='Figure 8: Structure of population_region_df, not showing all years in table to retain space but years go up to X2020')
```


```{r 3.5.1, results =T, echo=F}
#str(world)
head(data.frame(variable = names(world),
           class = sapply(world, typeof),
           first_values = sapply(world, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL), 10) %>% 
kable(caption='Figure 9: Structure of world, not showing geom feature in table as it has unique list of values per row and therefore is extremely large to display.')
```

## Clean Data

First thing that we need to drop unnecessary columns and set datatypes (factor, num, etc.).

### Clean *air_pollution_df*:
```{r 3.6, results =T, echo=F}
# Remove columns
air_pollution_df_cleaned <- subset(air_pollution_df, select = -c(Indoor.air.pollution..deaths.per.100.000., Outdoor.particulate.matter..deaths.per.100.000., Outdoor.ozone.pollution..deaths.per.100.000.))
# Set datatypes
air_pollution_df_cleaned$Entity = factor(air_pollution_df_cleaned$Entity)
air_pollution_df_cleaned$Code = factor(air_pollution_df_cleaned$Code)
air_pollution_df_cleaned$Year = factor(air_pollution_df_cleaned$Year)
# Rename columns
air_pollution_df_cleaned <- rename(air_pollution_df_cleaned, Country = Entity, ISO.alpha3.code = Code, Deaths.Air.Pollution.per.100k = Air.pollution..total...deaths.per.100.000.)
#str(air_pollution_df_cleaned)
data.frame(variable = names(air_pollution_df_cleaned),
           class = sapply(air_pollution_df_cleaned, typeof),
           first_values = sapply(air_pollution_df_cleaned, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL) %>% 
kable(caption='Figure 10: Structure of air_pollution_df_cleaned')
```

### Clean *gdp_df*:
```{r 3.7, results =T, echo=F}
# Remove columns
gdp_df_cleaned <- subset(gdp_df, select = -c(Indicator.Name, Indicator.Code))
# Pivot wide to long dataset (data melt)
gdp_df_cleaned <- gdp_df_cleaned %>%
  pivot_longer(
    cols = starts_with("X"), 
    names_to = "Year", 
    values_to = "GDP.USD", 
    values_drop_na = TRUE
  )
# Remove characters from column
gdp_df_cleaned$Year<-gsub("X","",as.character(gdp_df_cleaned$Year))
# Set datatypes
gdp_df_cleaned$Country.Name = factor(gdp_df_cleaned$Country.Name)
gdp_df_cleaned$Country.Code = factor(gdp_df_cleaned$Country.Code)
gdp_df_cleaned$Year = factor(gdp_df_cleaned$Year)
# Rename columns
gdp_df_cleaned <- rename(gdp_df_cleaned, Country = Country.Name, ISO.alpha3.code = Country.Code)
#str(gdp_df_cleaned)
data.frame(variable = names(gdp_df_cleaned),
           class = sapply(gdp_df_cleaned, typeof),
           first_values = sapply(gdp_df_cleaned, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL) %>% 
kable(caption='Figure 11: Structure of gdp_df_cleaned')
```

### Clean *population_region_df*:
```{r 3.8, results =T, echo=F}
# Remove columns
population_region_df_cleaned <- subset(population_region_df, select = -c(Notes, Type, Parent.code))
# Pivot wide to long dataset (data melt)
population_region_df_cleaned <- population_region_df_cleaned %>%
  pivot_longer(
    cols = starts_with("X"), 
    names_to = "Year", 
    values_to = "Population.thousands", 
    values_drop_na = TRUE
  )
# Remove characters from column
population_region_df_cleaned$Year<-gsub("X","",as.character(population_region_df_cleaned$Year))
population_region_df_cleaned <- as.data.frame(apply(population_region_df_cleaned, 2, function(x) gsub("\\s+", "", x))) 
# Set datatypes
population_region_df_cleaned$Country = factor(population_region_df_cleaned$Country)
population_region_df_cleaned$SDGRegion = factor(population_region_df_cleaned$SDGRegion)
population_region_df_cleaned$Country.code = factor(population_region_df_cleaned$Country.code)
population_region_df_cleaned$SubRegion = factor(population_region_df_cleaned$SubRegion)
population_region_df_cleaned$Year = factor(population_region_df_cleaned$Year)
population_region_df_cleaned$Population.thousands = as.numeric(population_region_df_cleaned$Population.thousands)
# Rename columns
population_region_df_cleaned <- rename(population_region_df_cleaned, M49.code = Country.code)
#str(population_region_df_cleaned)
data.frame(variable = names(population_region_df_cleaned),
           class = sapply(population_region_df_cleaned, typeof),
           first_values = sapply(population_region_df_cleaned, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL) %>% 
kable(caption='Figure 12: Structure of population_region_df_cleaned')
```

### Clean *population_region_df*:
```{r 3.9, results =T, echo=F}
# Set datatypes
country_codes_df$M49.code = factor(country_codes_df$M49.code)
country_codes_df$Country.or.Area = factor(country_codes_df$Country.or.Area)
country_codes_df$ISO.alpha3.code = factor(country_codes_df$ISO.alpha3.code)
country_codes_df$ISO.alpha2.code = factor(country_codes_df$ISO.alpha2.code)
#str(country_codes_df)
data.frame(variable = names(country_codes_df),
           class = sapply(country_codes_df, typeof),
           first_values = sapply(country_codes_df, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL) %>% 
kable(caption='Figure 13: Structure of country_codes_df')
```

### Clean *world*:
```{r 3.9.5, results =T, echo=F}
# Set datatypes
world$iso_a2 = factor(world$iso_a2)
# Remove columns
world_df_cleaned <- subset(world, select = c(iso_a2, geom))
#str(world_df_cleaned)
head(data.frame(variable = names(world_df_cleaned),
           class = sapply(world_df_cleaned, typeof),
           first_values = sapply(world_df_cleaned, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL), 1) %>% 
kable(caption='Figure 14: Structure of world_df_cleaned, not showing geom feature in table as it has unique list of values per row and therefore is extremely large to display.')
```

Note that we only have geometries for 175 countries, some will not be able to be plot on a map but that is okay.

### Final DataFrame Construction
Now let's merge our 4 datasets into one using a series of inner joins using country code and year as keys depending on the specific join. We are using inner joins because we want to drop all null values which would mean either a country does not have a country code or we have more years of data than our smallest year range (the air pollution dataset).

```{r 3.10, results =T, echo=F}
# Join datasets
final_df <- merge(x = air_pollution_df_cleaned, y = country_codes_df, by = 'ISO.alpha3.code')
final_df <- merge(x = final_df, y = gdp_df_cleaned, by = c('ISO.alpha3.code', 'Year'))
final_df <- merge(x = final_df, y = population_region_df_cleaned, by = c('M49.code', 'Year'))
final_df <- merge(x = final_df, y = world_df_cleaned, by.x = 'ISO.alpha2.code', by.y = 'iso_a2', all.x = TRUE) #left join
# Remove columns
final_df <- subset(final_df, select = -c(Country.or.Area, Country.y, Country))
# Calculate GDP per capita 
final_df$gdp.per.capita <- final_df$GDP.USD / (final_df$Population.thousands * 1000)
#str(final_df)
data.frame(variable = names(final_df),
           class = sapply(final_df, typeof),
           first_values = sapply(final_df, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL) %>% 
kable(caption='Figure 15: Structure of final_df')
```

```{r 3.11, include=TRUE, fig.align="center", echo=F}
# Convert to sf object so we can plot it on maps if needed
final_df_sf = st_as_sf(final_df)

# Choose relevant columns
final_df_sf_regions <- subset(final_df_sf, select = c(SDGRegion, SubRegion))
final_df_sf_intensities <- subset(final_df_sf, select = c(gdp.per.capita, Deaths.Air.Pollution.per.100k, Population.thousands))
```
Our dataset is finally ready to be analyzed.

# 4. EDA Summary

All necessary EDA was performed in the [Midterm Report](https://github.com/goebelclare/GitHub_Repo/blob/main/Midterm%20Project/Midterm-R_Markdown.html) where we looked at distributions for each key numerical variable in **Air Pollution Induced Deaths per 100k**, **Population**, **GDP per Capita**. We also looked into boxplots of these key numerical variables by **Regions** and **Sub Regions**. Interestingly, we observed that the same subregions that have low deaths caused by air pollution also have high GDP per capita comparatively.

Next, we checked for outliers and found that Deaths.Air.Pollution.per.100k definitely do not need to have outliers removed as it only represents 0.7% of the dataset. gdp.per.capita have higher percentage of classified outliers at 13.5%, however, we felt that keeping the extreme datapoints of this feature was important in our research and analysis to capture the true disproportionate distribution of wealth and progress across countries in our world.

Lastly, we explored a few choropleth maps to visually understand our dataset better.

We intentionally did not include any figures from EDA in this final report to preserve space. Please look at the [Midterm Report](https://github.com/goebelclare/GitHub_Repo/blob/main/Midterm%20Project/Midterm-R_Markdown.html) for details on our entire EDA process.

# 5. Main Research Question

Below is a rehash of our main research question from the Midterm report and we felt that the findings from this model was important enough to warrant inclusion in this final report as well.

## Do lower GDP countries have more deaths per 100k due to air pollution?

### Is there a correlation between GDP per capita and deaths caused by pollution? Is it linear? How strong is the correlation?

#### Linear Fit
Let's first look at the general fit on the overall data.

```{r 5.1, include=TRUE, fig.align="center", echo=F}
fit1 <- lm(Deaths.Air.Pollution.per.100k ~ gdp.per.capita, data=final_df_sf)
ggplot(final_df_sf, aes(gdp.per.capita, Deaths.Air.Pollution.per.100k)) +
  geom_point() +
  geom_smooth(method='lm', se=FALSE) +
  stat_regline_equation(label.y = 400, aes(label = ..eq.label..)) +
  stat_regline_equation(label.y = 350, aes(label = ..rr.label..))
```
: *Figure 15: Linear model (fit1) on overall data, deaths due to air pollution per 100k vs GDP per capita, 1990 to 2017.*

From the plot, we observed that there is indeed a negative correlation between deaths due to air pollution per 100k and GDP per capita. However, the strength of that relationship is not particularly strong as the R^2^ is really low at `r summary(fit1)$r.squared`. This means that only 29% of the variance experienced in deaths due to air pollution per 100k is caused by GDP per capita in a linear relationship.

#### Transformed Log Scale - Linear Fit

We then performed a log transformation and found that our linear regression fits much better.

fit2's summary statistics are:

```{r 5.3, include=TRUE, fig.align="center", echo=F}
fit2 <- lm(log(Deaths.Air.Pollution.per.100k) ~ log(gdp.per.capita), data=final_df_sf)
summary(fit2)
# print(vif(fit2))
```

We re-plotted the linear model and here were the results.

```{r 5.3.3, include=TRUE, fig.align="center", echo=F}
ggplot(final_df_sf, aes(log(gdp.per.capita), log(Deaths.Air.Pollution.per.100k))) +
  geom_point() +
  geom_smooth(method='lm', se=FALSE) +
  stat_regline_equation(label.y = 7, aes(label = ..eq.label..)) +
  stat_regline_equation(label.y = 6, aes(label = ..rr.label..))
```
: *Figure 16: Fitting to a log(y) = (m)(log(x)) + b curve yields much stronger relationship.*

Across the board, the strength of our linear relationship increases dramatically when first transforming both features by the log() function first. The new R^2^ is now `r summary(fit2)$r.squared` which means around 74% of the variance in our target feature can be explained by this mathematical relationship.

We can then predict a country's deaths caused from air pollution in a given year by using the country's GDP per capita with the following equation: 


$$
log(Deaths_{from~air~pollution|per~year|per~country} / 100,000) = 7.38778 - 0.38952 * log(GDP_{per capita}) ~~~~~~~~~~~~~~~~  eqn (1)
$$

or solving for our target variable:



$$
Deaths_{from~air~pollution|per~year|per~country} = 10^{7.38778 - 0.38952 * log(GDP per capita)} * 100,000 ~~~~~~~~~~~~~~~~ eqn (2)
$$

### Is there a difference in means of death caused by pollution between low, mid, and high GDP per capita?

We all know that correlation does not necessarily mean causation. Let us dig a little deeper and test if means of deaths caused by air pollution per 100k across different GDP per capita levels are equal or not.

#### One-Way ANOVA Test

We started off by performing a One-Way ANOVA test to determine if the means of deaths caused by air pollution per 100k across different GDP per capita levels are equal or not.

H~0~: $\mu$~deaths_lowest_gdp~ = $\mu$~deaths_low_gdp~ = $\mu$~deaths_medium_gdp~ = $\mu$~deaths_high_gdp~

H~1~: At least one of $\mu$~deaths_lowest_gdp~, $\mu$~deaths_low_gdp~, $\mu$~deaths_medium_gdp~, $\mu$~deaths_high_gdp~ is not equal

We will use an $\alpha$ value of 0.05.

```{r Q5.9, include=TRUE, echo=F}
# divide df$am.spent 
final_df_sf$qnt <- cut(final_df_sf$gdp.per.capita , breaks=quantile(final_df_sf$gdp.per.capita, na.rm = TRUE),
                                    labels=1:4, include.lowest=TRUE)
# check ranges
tapply(final_df_sf$gdp.per.capita , final_df_sf$qnt , range)
deaths_aov = aov(Deaths.Air.Pollution.per.100k ~ qnt, data=final_df_sf)
deaths_aovsummary = summary(deaths_aov)
deaths_aovsummary
p = deaths_aovsummary[[1]][["Pr(>F)"]][[1]]
```
The p-value~test1~ is `r format(p, scientific=T)`, which is lower than $\alpha$~0.05~. Therefore, we reject our null hypothesis that $\mu$~deaths_lowest_gdp~ = $\mu$~deaths_low_gdp~ = $\mu$~deaths_medium_gdp~ = $\mu$~deaths_high_gdp~. This means that there is statistically significant that at least one of the means of deaths in low, medium, and high GDP per capita are not the same. 

#### 2-Sample T-Tests

We will conduct 6 2-sample t-tests to determine if each of the groupings are different from each other:

* Lowest GDP per capita's deaths does not equal Low GDP per capita's deaths
    + H~0~: $\mu$~deaths_lowest_gdp~ = $\mu$~deaths_low_gdp~
    + H~1~: $\mu$~deaths_lowest_gdp~ != $\mu$~deaths_low_gdp~
* Low GDP per capita's deaths does not equal Medium GDP per capita's deaths
    + H~0~: $\mu$~deaths_low_gdp~ = $\mu$~deaths_medium_gdp~
    + H~1~: $\mu$~deaths_low_gdp~ != $\mu$~deaths_medium_gdp~
* Medium GDP per capita's deaths does not equal High GDP per capita's deaths
    + H~0~: $\mu$~deaths_medium_gdp~ = $\mu$~deaths_high_gdp~
    + H~1~: $\mu$~deaths_medium_gdp~ != $\mu$~deaths_high_gdp~
* Lowest GDP per capita's deaths does not equal High GDP per capita's deaths
    + H~0~: $\mu$~deaths_lowest_gdp~ = $\mu$~deaths_high_gdp~
    + H~1~: $\mu$~deaths_lowest_gdp~ != $\mu$~deaths_high_gdp~
* Lowest GDP per capita's deaths does not equal Medium GDP per capita's deaths
    + H~0~: $\mu$~deaths_lowest_gdp~ = $\mu$~deaths_medium_gdp~
    + H~1~: $\mu$~deaths_lowest_gdp~ != $\mu$~deaths_medium_gdp~
* Low GDP per capita's deaths does not equal Highest GDP per capita's deaths
    + H~0~: $\mu$~deaths_low_gdp~ = $\mu$~deaths_high_gdp~
    + H~1~: $\mu$~deaths_low_gdp~ != $\mu$~deaths_high_gdp~
    
We used a two sample t-test for each and used an $\alpha$ value of 0.05.

**Test 1**:

Conclusion of test1: p-value~test1~ is less than $\alpha$~0.05~, therefore we reject our null hypothesis that $\mu$~deaths_lowest_gdp~ is equal to $\mu$~deaths_low_gdp~ and accept our alternative hypothesis.

**Test 2**:

Conclusion of test2: p-value~test2~ is less than $\alpha$~0.05~, therefore we reject our null hypothesis that $\mu$~deaths_low_gdp~ is equal to $\mu$~deaths_medium_gdp~ and accept our alternative hypothesis.

**Test 3**:

Conclusion of test3: p-value~test3~ is less than $\alpha$~0.05~, therefore we reject our null hypothesis that $\mu$~deaths_medium_gdp~ is equal to $\mu$~deaths_high_gdp~ and accept our alternative hypothesis.

**Test 4**:

Conclusion of test4: p-value~test4~ is less than $\alpha$~0.05~, therefore we reject our null hypothesis that $\mu$~deaths_lowest_gdp~ is equal to $\mu$~deaths_high_gdp~ and accept our alternative hypothesis.

**Test 5**:

Conclusion of test5: p-value~test5~ is less than $\alpha$~0.05~, therefore we reject our null hypothesis that $\mu$~deaths_lowest_gdp~ is equal to $\mu$~deaths_medium_gdp~ and accept our alternative hypothesis.

**Test 6**:

Conclusion of test6: p-value~test6~ is less than $\alpha$~0.05~, therefore we reject our null hypothesis that $\mu$~deaths_low_gdp~ is equal to $\mu$~deaths_high_gdp~ and accept our alternative hypothesis.

###  Midterm Main Research Results
From all of our tests above, we can confirm that the means of deaths caused by air pollution are statistically significant when grouped by different levels of GDP per capita. This reinforces the idea that deaths caused by air pollution has a significant relationship with GDP per capita and the model can be quantified by *Equation 2*:

$$
Deaths_{from~air~pollution|per~year|per~country} = 10^{7.38778 - 0.38952 * log(GDP per capita)} * 100,000 ~~~~~~~~~~~~~~~~ eqn (2)
$$

The strength of the correlation can be quantified by our R^2^ value of `r summary(fit2)$r.squared` from Figure 16.

# 6. Smart Questions for Further Modeling 

### 1. What are the impacts of population size from GDP and Deaths due to Air Pollution globally?

1. Categorizing GDP into low (0), medium(1) and high(2)

```{r}
SQ6 <- final_df
library(dplyr)
groupings_pop <- SQ6 %>% mutate(population_grouping = case_when(Population.thousands >=  100001 & Population.thousands <= 1000000000 ~ 2,
                                             Population.thousands >= 50001  & Population.thousands <= 100001 ~ 1,
                                             Population.thousands >= 0 & Population.thousands <= 50000 ~ 0)) # end function
```

2. Building a logit model GDP as predictor on Population  

```{r}
pop_gdpLogit <- glm(population_grouping ~ groupings_pop$gdp.per.capita, data = groupings_pop)
```
```{r}
summary(pop_gdpLogit)
```  

3. Bulding a logit model GDP and Deaths due to Air Population as predictor on Population  

```{r}
pop_gdp_deathsLogit <- glm(population_grouping ~ groupings_pop$gdp.per.capita + groupings_pop$Deaths.Air.Pollution.per.100k, data = groupings_pop)
```
```{r}
summary(pop_gdp_deathsLogit)
```  

### 2. What are the effects of (low or high) GDP and population size on deaths due to air pollution in Sub-Saharan Africa?


Here we use decision tree classification algorithm to predict which countries in Sub-Saharan Africa are more likely to have lower or higher deaths per 100,000 due to air pollution. We use predictors -GDP per capita and population size in thousands. 

As we learned this semester, a qualitative response warrants the utilization of a classification tree. This helps us predict you predict that each observation belongs to the most commonly occurring class of training observations in the region to which it belongs.

Below, we subset our data to only relect Sub-Saharan countries, and then we create a new variable `deaths` that recategorizes existing variable  `Deaths.Air.Pollution.per.100k` into "high" or "low" based on the median deaths due to air pollution from 1990 to 2017. 

Since our median is 143. 5, we set `deaths` = "high" if `Deaths.Air.Pollution.per.100k` is greater than or equal to 143, and `deaths` = "low" if `Deaths.Air.Pollution.per.100k` is less than 143. Lastly, we transform the `deaths` variable into a factor variable

```{r Q2, include=TRUE, echo=F}
loadPkg("ISLR")
loadPkg("tree")
loadPkg("caTools")
loadPkg("ggplot2")
loadPkg("rpart.plot")
loadPkg("rpart")
loadPkg("party")
loadPkg("dplyr")
loadPkg("magrittr")
loadPkg("rattle")
loadPkg("caTools")
library(caret)


options(scipen=999)
set.seed(42)
options(digits=10)

##Subset the data to only reflect countries in Sub-Saharan 
names(final_df)
final_df_africa <-subset(final_df,SDGRegion == "SUB-SAHARANAFRICA")
#Remove NA values
final_df_africa <- na.omit(final_df_africa)

##Look at data
head(final_df_africa)
str(final_df_africa)
summary(final_df_africa$Deaths.Air.Pollution.per.100k)

#Deaths variable
final_df_africa$deaths <- ifelse(final_df_africa$Deaths.Air.Pollution.per.100k<143, 
                                 "low",
                                 "high")
final_df_africa$deaths <- as.factor(final_df_africa$deaths)
```

#### Train the Model

The next thing we do is create a train and test set, this is done to train our model (train set) and test the prediction (test set). As taught in class, we split the data 80/20, 80% to train the model (991 observations), 20% to make predictions (248 observations). We verified this randomization process and see that low deaths in both sets are about 49%.

Next we build and train our model as `deaths ~ gdp.per.capita + Population.thousands` and plot the tree. It is important to note that the rpart() function we employ uses the Gini impurity measure to split the nodes. The Gini Impurity measure is 

```{r Q2.1, include=TRUE, echo=F}

#Split 
split = sample.split(final_df_africa$deaths, SplitRatio = 0.80)
train = subset(final_df_africa, split == TRUE)
test = subset(final_df_africa, split == FALSE)

#Check proportions
trainprop <- prop.table(table(train$deaths))
print(trainprop)
testprop<-prop.table(table(test$deaths))
print(testprop)

#Model
afit <- rpart(deaths ~ gdp.per.capita + Population.thousands,data=train, method="class", control = list(maxdepth = 4))
# plot tree 
rpart.plot(afit, extra = 106, main="Classification Tree for Deaths due to Air Pollution in Sub-Sahara Africa ")
summary(afit) # detailed summary of splits
printcp(afit) # display the results 
plotcp(afit)

```

As shown above, our decision tree shows at the root node that 50% of countries in Sub-Saharan Africa have high deaths due to air pollution. Then, we see that 68% of these countries have GDP per capita that is less than $1,065 with probability of high deaths due to air pollution (32%). Then we see that out of these countries, 44% has gdp per capita NOT greater than $348 with probability of high deaths due to air pollution- 45% . Lastly, we see that 37% of the countries have population less than about 26,000,000 and GDP per capita greater than $348 and less than $1,065 -  with probability of high deaths due to air pollution at 37%.

```{r, include = T}
#Tree Plot
post(afit, file = "afit.ps", title = "Classification Tree for Deaths due to Air Pollution in Sub-Sahara Africa")
```

#### Predict

Here, we use the above test tree to predict it on our test set. We are predicting which countries are more likely to have higher deaths due to air pollution. 

```{r Q2.2, include=TRUE, echo=F}
#test
loadPkg("caret") 

apred <- predict(afit,test,type="class")
summary(apred) # detailed summary of splits

```


#### Evaluation

The next thing we do is evaluate our model's performance using the confusion matrix, and from that, the accuracy test.

*As we all know,*
*TP: (True Positive) means predicted values correctly predicted as positive*
*FP: (False Positive) means predicted values incorrectly predicted an actual positive*
*FN: (False Negative) means positive values predicted as negative*
*TN: (True Negative) means predicted values correctly predicted as an actual negative*



```{r Q2.3, include=T}
#Evaluate

# Confusion matrix and Accuracy test
cm<-with(test, table(apred, deaths))
print(cm)
```
```{r CM, include=T}
xkabledply(cm, "confusion matrix")
```
```{r AT, include=T}
accuracy <- sum(diag(cm)) / sum(cm)
print(paste('Accuracy for test', accuracy))

```

So we see above that our model accurately predicted 110 countries with high deaths due to air pollution (True negative) and 74 countries with low deaths due to air pollution (True positive), however it misclassified 49 countries for the former (False positive) and 15 countries for the latter(True negative).

The overall accuracy is `74`%.  Here the accuracy-test from the confusion matrix is calculated and is found to be 0.741935 Hence this model is found to predict with an accuracy of 74 %.

Cross-Entropy: A third alternative, which is similar to the Gini Index, is known as the Cross-Entropy or Deviance:


#### Prune the tree

The last thing we want to do here is prune our tree, this will minimize overfitting the data by minimizing the cross-validated error. what is overfitting? what is cp?

```{r prune}
#prune the tree 
pafit <- prune(afit, cp = afit$cptable[2,"CP"])
printcp(pafit)
#cp is cost complexity and has to be minimum.

# plot the pruned tree 
fancyRpartPlot(pafit,main="Pruned Classification Tree for Deaths due to Air Polution")

```

```{r Q2.4, include=TRUE, echo=F}
#test 2
papred <- predict(pafit,test,type="class")
summary(papred) # detailed summary of splits

# Accuracy test
cm2 <-with(test, table(papred, deaths))
accuracy2 <- sum(diag(cm2)) / sum(cm2)
print(paste('Accuracy for test', accuracy))

```

As shown above, accuracy is now `74`%. Pruning had little effect even though the tree is now simpler. So, we have a model that can predict high deaths due to air pollution with 74% accuracy.


```{r,}
# create attractive postcript plot of tree 
post(afit, file = "afit.ps", title = "Pruned Classification Tree for Deaths due to Air Pollution in Sub-Sahara Africa")

```

#### How can we improve this model in the future?
Instead of of an individual tree, we can employ other techniques such as bagging, random forests, and boosting, which will significantly improve our predictive performance!


### 3. Can we let the data tell us what type of groupings exist in our dataset? How consistent are they to our preconceived groupings such as region or developed vs developing countries? 

We wanted to better understand what types of groupings exist within our dataset. More concretely, we wanted to put aside our preconceived presumptions about our dataset and create a *K-Means clustering model* and allow the the data to guide us to the possible clusters that may exist within our data.

*K-Means clustering* is an unsupervised machine learning algorithm that is very useful to parse the dataset and identify *K* number of groups where observations within each group have high similarity. 

First, let's create an index label to allow for clustering.

```{r Q6.3.0, include=TRUE, echo=F}
final_df_cluster <- final_df

final_df_cluster$index <- paste(final_df_cluster$Country.x, final_df_cluster$AD, sep="")

final_df_cluster <- final_df_cluster %>% select(index, Deaths.Air.Pollution.per.100k, gdp.per.capita, SDGRegion, Population.thousands)

options(warn = - 1)   
final_df_cluster = aggregate(final_df_cluster, by=list(index_=final_df_cluster$index, region=final_df_cluster$SDGRegion), FUN=mean)

final_df_cluster <- subset(final_df_cluster, select = -c(index, SDGRegion))

final_df_cluster <- final_df_cluster[!duplicated(final_df_cluster$index_),]

rownames(final_df_cluster) <- final_df_cluster$index_

knitr::kable(head(final_df_cluster), format = "html", caption="Figure 6.3-0: Head of final_df_cluster")
```
Next, let's select only the numerical values from our dataset.

```{r Q6.3.1, include=TRUE, echo=F}
final_df_numerical <- select_if(final_df_cluster, is.numeric)  

#remove rows with missing values
final_df_numerical <- na.omit(final_df_numerical)

#str(final_df_numerical)
data.frame(variable = names(final_df_numerical),
           class = sapply(final_df_numerical, typeof),
           first_values = sapply(final_df_numerical, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL) %>% 
kable(caption='Figure 6.3-1: Structure of final_df_numerical')
```

#### Optimal *K* Clusters
Let's try to find the optimal *K* value to achieve best clustering results. The 2 that we will try are using: 

1. Elbow Method with Total Within Sum of Squares  
2. Looking at the Gap Statistics

*Elbow Method with Total Within Sum of Squares*

```{r Q6.3.2, include=TRUE, echo=F}
final_df_numerical_scaled <- scale(final_df_numerical)
fviz_nbclust(final_df_numerical_scaled, kmeans, method = "wss")+ 
  geom_vline(xintercept = 4, linetype = 2)+ 
  geom_vline(xintercept = 7, linetype = 2)
```
: *Figure 6.3-2: Finding the optimal number of clusters using the Within Sum of Squares Method.*

From the total Within Sum of Squares plot, we find that the optimal number of *K* seems to be at 4 using the Elbow method which identifies the *K* number where the Total Sum of Squares begins to level off, or where adding additional *K* clusters only improves our model marginally.

*Looking at the Gap Statistics*

```{r Q6.3.3, include=TRUE, echo=F}
#calculate gap statistic based on number of clusters
gap_stat <- clusGap(final_df_numerical_scaled,
                    FUN = kmeans,
                    nstart = 25,
                    K.max = 10,
                    B = 50)

#plot number of clusters vs. gap statistic
fviz_gap_stat(gap_stat)+ 
  geom_vline(xintercept = 4, linetype = 2)+ 
  geom_vline(xintercept = 7, linetype = 2)
```
: *Figure 6.3-3: Finding the optimal number of clusters using the Gap Statistic.*

From the Gap Statistic plot, we find that the optimal number of *K* seems to be at 10 with the highest gap statistic, however, we observed using the Elbow method that the Total Sum of Squares begins to level off from 4 to 10. We will stick with using *K* = 4.

#### Perform K-Means Clustering with Optimal *K*

We perform a K-Means clustering analysis with a *K* of 4 and here are the results below.


```{r Q6.3.4, include=TRUE, echo=F}
#make this example reproducible
set.seed(42)

#perform k-means clustering with k = 4 clusters
km <- kmeans(final_df_numerical_scaled, centers = 4, nstart = 25)

km_centers = km$centers
km_centers <- cbind(Cluster = rownames(km_centers), km_centers)
rownames(km_centers) <- 1:nrow(km_centers)

xkabledply(km_centers, title="Figure 6.3-4: K-Means Clustering Average Values per Cluster")
```
```{r Q6.3.5, include=TRUE, echo=F}
#view results
km_size = as.data.frame(km$size)
colnames(km_size) <- c("Observations with Each Cluster")

km_size <- cbind(Cluster = rownames(km_size), km_size)
rownames(km_size) <- 1:nrow(km_size)

xkabledply(km_size, title="Figure 6.3-5: Number of Observations Within Each Cluster")
```

```{r Q6.3.6, include=TRUE, echo=F}
#view results
km_withinss= as.data.frame(km$withinss)
colnames(km_withinss) <- c("Total Sum of Squares with Each Cluster")

km_withinss <- cbind(Cluster = rownames(km_withinss), km_withinss)
rownames(km_withinss) <- 1:nrow(km_withinss)

xkabledply(km_withinss, title="Figure 6.3-6: Total Sum of Squares Within Each Cluster")
```

Let's take a look at clusters visually. Interestingly, our model has grouped China and India into their own separate cluster, Cluster 2. Clusters 4, 3, and 1 can be roughly characterized by high GDP per captita nations, medium GDP per capita nations, and low GDP per capita nations'. 

```{r Q6.3.7, include=TRUE, echo=F}
#plot results of final k-means model
fviz_cluster(km, data = final_df_numerical_scaled)
```
: *Figure 3.6-7: Visualing K-Means Clustering Model.*

Let's take a closer look at each cluster's breakdown of subregions more closely to determine what type of discrepancies we find between each cluster.

```{r Q6.3.8, include=TRUE, echo=F}
kmeans_basic_df <- data.frame(Cluster = km$cluster, final_df_cluster)

kmeans_group_df = kmeans_basic_df %>%
  group_by(Cluster, region) %>%
  summarize(Percentage=n() / nrow(.) )

# head of df
#head(kmeans_group_df)

# Stacked + percent
ggplot(data = kmeans_group_df, aes(fill=region, y=Percentage, x=Cluster)) + 
    geom_bar(position="fill", stat="identity")+
  ggtitle("Frequency % of SDGRegion by Clusters") +
  theme(plot.title = element_text(hjust = 0.5))
```
: *Figure 6.3-8: Frequency % of SDGRegion by Clusters.*

Interestingly, we observe that Cluster 1 is disproportionately comprised of countries in Sub-Saharan Africa with large representations from Oceania, Eastern & South-Eastern Asia, and Central & Southern Asia. Cluster 2 is the one cluster comprised solely of China and India. Cluster 3 has a much larger proportion of countries from Europe, Northen America, and Northern Africa & Western Asia. Cluster 4 is similar to Cluster 3 except it does not have countries from Northern America and has more countries from Sub-Saharan Africa and Central & Southern Asia. 

### 4. Can we make a prediction of the future GDP by considering the population size, location, and the reation of population and deaths due to air pollution? 

For our major model we make a nice prediction for GDP through total deaths caused by air pollution, so as we can see that through the distribution of the data, there are strong relationships between total deaths caused by air pollution, deaths caused by indoor air pollution, and deaths caused by outdoor air pollution.


```{r 7, include=TRUE}
# select what we need
# total
#ggplot(total3, aes(x=Year, y=air_pollution_total)) +
#    geom_bar(stat='identity', position='dodge')

# indoor
#ggplot(total3, aes(x=Year, y=air_pollution_indoor)) +
#    geom_bar(stat='identity', position='dodge')
# outdoor particulate
#ggplot(total3, aes(x=Year, y=air_pollution_outdoorP)) +
#    geom_bar(stat='identity', position='dodge')
# outdoor ozone 
#ggplot(total3, aes(x=Year, y=air_pollution_outdoorO)) +
#    geom_bar(stat='identity', position='dodge')


air_pollution_df_cleaned1 <- air_pollution_df
```

So it seems like we can also get a nice GDP prediction by using deaths caused by indoor air pollution and deaths caused by outdoor air pollution as the basis of the prediction model.

```{r 7.1, include=TRUE}
# make Entity and year factor
air_pollution_df_cleaned1$Entity = factor(air_pollution_df_cleaned1$Entity)
air_pollution_df_cleaned1$Code = factor(air_pollution_df_cleaned1$Code)
air_pollution_df_cleaned1$Year = factor(air_pollution_df_cleaned1$Year)
```
```{r 7.2, include=TRUE}
# polution
air_pollution_df_cleaned1 <- rename(air_pollution_df_cleaned1, Country = Entity, ISO.alpha3.code = Code, Deaths.Air.Pollution.per.100k = Air.pollution..total...deaths.per.100.000. , Deaths.Air.Pollution.Indoor.per.100k = Indoor.air.pollution..deaths.per.100.000., Deaths.Air.Pollution.OutdoorP.per.100k = Outdoor.particulate.matter..deaths.per.100.000., Deaths.Air.Pollution.OutdoorO.per.100k = Outdoor.ozone.pollution..deaths.per.100.000.)


# population
#population_region_df_cleaned <- subset(population_region_df, select = -c(Notes, Type, Parent.code))

#population_region_df_cleaned <- population_region_df_cleaned %>%
#  pivot_longer(
#    cols = starts_with("X"), 
#    names_to = "Year", 
 #   values_to = "Population.thousands", 
  #  values_drop_na = TRUE
#  )

# population_region_df_cleaned$Year<-gsub("X","",as.character(population_region_df_cleaned$Year))
# population_region_df_cleaned <- as.data.frame(apply(population_region_df_cleaned, 2, function(x) gsub("\\s+", "", x))) 

# population_region_df_cleaned$Country = factor(population_region_df_cleaned$Country)
# population_region_df_cleaned$SDGRegion = factor(population_region_df_cleaned$嚜燙DGRegion)
# population_region_df_cleaned$Country.code = factor(population_region_df_cleaned$Country.code)
# population_region_df_cleaned$SubRegion = factor(population_region_df_cleaned$SubRegion)
# population_region_df_cleaned$Year = factor(population_region_df_cleaned$Year)
# population_region_df_cleaned$Population.thousands = as.numeric(population_region_df_cleaned$Population.thousands)

# population_region_df_cleaned <- rename(population_region_df_cleaned, M49.code = Country.code)

# country_codes_df$M49.code = factor(country_codes_df$M49.code)
# country_codes_df$Country.or.Area = factor(country_codes_df$嚜澧ountry.or.Area)
# country_codes_df$ISO.alpha3.code = factor(country_codes_df$ISO.alpha3.code)
# country_codes_df$ISO.alpha2.code = factor(country_codes_df$ISO.alpha2.code)

# world$iso_a2 = factor(world$iso_a2)
# 
# world_df_cleaned <- subset(world, select = c(iso_a2, geom))

# merge
final_dfc <- merge(x = air_pollution_df_cleaned1, y = country_codes_df, by = 'ISO.alpha3.code')

final_dfc <- merge(x = final_dfc, y = gdp_df_cleaned, by = c('ISO.alpha3.code', 'Year'))
final_dfc <- merge(x = final_dfc, y = population_region_df_cleaned, by = c('M49.code', 'Year'))
final_dfc <- merge(x = final_dfc, y = world_df_cleaned, by.x = 'ISO.alpha2.code', by.y = 'iso_a2', all.x = TRUE) #left join

# Remove columns
final_dfc <- subset(final_dfc, select = -c(Country.or.Area, Country.y, Country))

# Calculate GDP per capita 
final_dfc$gdp.per.capita <- final_dfc$GDP.USD / final_dfc$Population.thousands


final_dfc$Deaths.Air.Pollution.Outdoor.Total.per.100k <- final_dfc$Deaths.Air.Pollution.OutdoorO.per.100k + final_dfc$Deaths.Air.Pollution.OutdoorP.per.100k
```

For the first model, we build a linear model using 'gdp.per.capita' and 'Deaths.Air.Pollution.Indoor.per.100k'.

```{r 7.3, include=TRUE}

final_df_sfc = st_as_sf(final_dfc)
fit2c <- lm(gdp.per.capita ~Deaths.Air.Pollution.Indoor.per.100k, data=final_df_sfc)

summary(fit2c)

ggplot(final_df_sfc, aes(gdp.per.capita, Deaths.Air.Pollution.Indoor.per.100k)) +
  geom_point() +
  geom_smooth(method='lm', se=FALSE) +
  stat_regline_equation(label.y = 350, aes(label = ..eq.label..)) +
  stat_regline_equation(label.y = 400, aes(label = ..rr.label..))

```
: *Figure 6.4-1: Deaths due to Indoor Air Pollution vs GDP per capita.*

The R-squared value of this model is 0.22, which is a really bad result. So follow the steps in the major model building, now we put these two features into a log() and it should performed better.


```{r 7.4, results =T, echo=F}
fit2l <- lm(log(gdp.per.capita) ~log(Deaths.Air.Pollution.Indoor.per.100k), data=final_df_sfc)

summary(fit2l)

ggplot(final_df_sfc, aes(log(gdp.per.capita), log(Deaths.Air.Pollution.Indoor.per.100k))) +
  geom_point() +
  geom_smooth(method='lm', se=FALSE) +
  stat_regline_equation(label.y = 12, aes(label = ..eq.label..)) +
  stat_regline_equation(label.y = 10, aes(label = ..rr.label..))

```
: *Figure 6.4-2: Log Deaths due to Indoor Air Pollution vs Log GDP per capita.*

As we can see, although it performed much better with a R-squared value 0.68 but this is still not good as the major model.

Next we try the deaths caused by outdoor air pollution 'Deaths.Air.Pollution.Outdoor.Total.per.100k'.


```{r 7.5, results =T, echo=F}
fit3c <- lm(gdp.per.capita ~Deaths.Air.Pollution.Outdoor.Total.per.100k, data=final_df_sfc)

summary(fit3c)

ggplot(final_df_sfc, aes(gdp.per.capita, Deaths.Air.Pollution.Outdoor.Total.per.100k)) +
  geom_point() +
  geom_smooth(method='lm', se=FALSE) +
  stat_regline_equation(label.y = 150, aes(label = ..eq.label..)) +
  stat_regline_equation(label.y = 200, aes(label = ..rr.label..))

```
: *Figure 6.4-3: Deaths due to Outdoor Air Pollution vs GDP per capita.*

The performence of this model is also bad, with a R-squared value 0.036, so we put the features in the log() too.


```{r 7.6, results =T, echo=F}
fit3l <- lm(log(gdp.per.capita) ~log(Deaths.Air.Pollution.Outdoor.Total.per.100k), data=final_df_sfc)
summary(fit3l)
ggplot(final_df_sfc, aes(log(gdp.per.capita), log(Deaths.Air.Pollution.Outdoor.Total.per.100k))) +
  geom_point() +
  geom_smooth(method='lm', se=FALSE) +
  stat_regline_equation(label.y = 10, aes(label = ..eq.label..)) +
  stat_regline_equation(label.y = 12, aes(label = ..rr.label..))

```
: *Figure 6.4-4: Log Deaths due to Outdoor Air Pollution vs Log GDP per capita.*

A surprised point is that although we put the variables into log(), the performance of model is still bad and even worse. The R-squared value of this model is 0.0039.

Finally, we are going to test build a model base on both deaths caused by outdoor  and indoor air pollution. To check if this model also works bad.


```{r 7.7, results =T, echo=F}
fit4c <- lm(gdp.per.capita ~Deaths.Air.Pollution.Indoor.per.100k + Deaths.Air.Pollution.Outdoor.Total.per.100k, data=final_df_sfc)

summary(fit4c)

ggplot(final_df_sfc, aes(gdp.per.capita, Deaths.Air.Pollution.Outdoor.Total.per.100k+ Deaths.Air.Pollution.Indoor.per.100k)) +
  geom_point() +
  geom_smooth(method='lm', se=FALSE) +
  stat_regline_equation(label.y = 400, aes(label = ..eq.label..)) +
  stat_regline_equation(label.y = 450, aes(label = ..rr.label..))
```
: *Figure 6.4-5: Deaths due to Indoor + Outdoor Air Pollution vs GDP per capita.*

The R-squared value of this model is 0.29. 
Next we put these variables into log().


```{r 7.8, results =T, echo=F}

fit4l <- lm(log(gdp.per.capita) ~log(Deaths.Air.Pollution.Outdoor.Total.per.100k)+log(Deaths.Air.Pollution.Indoor.per.100k), data=final_df_sfc)

summary(fit4l)

ggplot(final_df_sfc, aes(log(gdp.per.capita), log(Deaths.Air.Pollution.Outdoor.Total.per.100k)+ log(Deaths.Air.Pollution.Indoor.per.100k))) +
  geom_point() +
  geom_smooth(method='lm', se=FALSE) +
  stat_regline_equation(label.y = 25, aes(label = ..eq.label..)) +
  stat_regline_equation(label.y = 30, aes(label = ..rr.label..))
```
: *Figure 6.4-6: Log Deaths due to Indoor + Outdoor Air Pollution vs Log GDP per capita.*

For this model the R-squared value is 0.69. This is actually not a bad result but when comparing to the major model using total deaths caused by air pollution, 0.69 is not good enough for predicting GDP. 

We can get the conclusion that we can not get a nice GDP prediction by using deaths caused by indoor air pollution and deaths caused by outdoor air pollution as the basis of the prediction model.


# 7. Conclusion SMART Modeling

1. For the Logit Regression, we observed *small p-values indicating that all the coefficients are found to be significant*. GDP has a positive effect on population, but deaths due to air pollution have a negative effect on population. 

2. As shown above, post-pruning, our *accuracy is still 74%*. So, pruning had little effect even though the tree is now much simpler. Therefore, we have a model that can *predict high deaths due to air pollution with 74%  accuracy*.

3. For the clustering, it is really interesting to observe that the main clusters 1, 3, and 4 have large discrepancies in regional representation while the data we used for clustering did not have any explicit geospatial components. This can mean that regionality, although may not be the cause, does have some correlation in determining the groups of factors in *GDP per Capita*, *Population*, and *Deaths due to Air Pollution per 100k*.

4. Although death caused by indoor air pollution and outdoor air pollution seems to have a *strong relationship with total death caused by air pollution*, but we *can’t accurately predict GDP* through death caused by indoor and outdoor air pollution.

# 8. Bibliography

| Number                                                      | APA Citation                                                                                       |
|-----------------------------------------------------------|--------------------------------------------------------------------------------------------|
| 1                                        | Robin Lovelace, J. N. (n.d.). Chapter 8 Making maps with R: Geocomputation with R. Retrieved October 28, 2021, from https://geocompr.robinlovelace.net/adv-map.html                                  |
| 2                                     | Robin Lovelace, J. N. (2021, October 28). Chapter 2 Geographic data in R: Geocomputation with R. Retrieved from https://geocompr.robinlovelace.net/spatial-class.html#intro-sf                     |
| 3                                          | Hadley Wickham, D. N. (2021, October 28). 6 Maps. Retrieved from https://ggplot2-book.org/maps.html                                                |
| 4                                      | Customizing ggplot2 color and fill scales. (2021, October 28). Retrieved from https://spielmanlab.github.io/introverse/articles/color_fill_scales.html           |
| 5                                          | Logarithmic Functions. (2021, October 28). Retrieved from https://saylordotorg.github.io/text_intermediate-algebra/s10-03-logarithmic-functions-and-thei.html         |
| 6                                          | K-Means Clustering in R. (2021, December 3). Retrieved from https://www.statology.org/k-means-clustering-in-r/         |
| 7                                          | Confusion Matrix in Machine Learning. (2021, December 3). Retrieved from https://www.guru99.com/confusion-matrix-machine-learning-example.html         |
: Figure 8.1: References
